{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes dictionary \n",
    "classes_dict={0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',6:'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defintion of load_dataset()\n",
    "def load_dataset():\n",
    "    import csv\n",
    "    with  open('C:\\\\Users\\\\Admin\\\\My Projects\\\\Emotion Recognition\\\\dataset\\\\fer2013.csv','r') as f:\n",
    "        data=csv.reader(f)\n",
    "        X=[]\n",
    "        Y=[]\n",
    "        i=1\n",
    "        for row in data:\n",
    "            if i:    #skip first row (header)\n",
    "                i=0\n",
    "                continue    \n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(n) for n in row[1].split(' ')])\n",
    "    return (np.array(X),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 48, 48, 1) (35887, 1)\n"
     ]
    }
   ],
   "source": [
    "#load dataset from csv file\n",
    "X,Y=load_dataset()\n",
    "\n",
    "#normalizing the data\n",
    "X=X/255\n",
    "\n",
    "#reshape the data\n",
    "X=X.reshape((X.shape[0],48,48,1))\n",
    "Y=Y.reshape(Y.shape+(1,))\n",
    "\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(0)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.08,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the train and test labels into one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_train_oh=to_categorical(Y_train,len(classes_dict))\n",
    "Y_test_oh=to_categorical(Y_test,len(classes_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of create_model()\n",
    "def create_model():\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input,Conv2D,Dense,BatchNormalization,Activation\n",
    "    from tensorflow.keras.layers import Dropout,MaxPooling2D,AveragePooling2D,Flatten\n",
    "\n",
    "    inputs=Input(shape=(48,48,1))\n",
    "\n",
    "    X=Conv2D(filters=32,kernel_size=(7,7),padding='same')(inputs)\n",
    "    X=BatchNormalization(axis=-1)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D((2,2))(X)\n",
    "    X=Dropout(.25)(X)\n",
    "\n",
    "    X=Conv2D(filters=64,kernel_size=(3,3),padding='same')(X)\n",
    "    X=BatchNormalization(axis=-1)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D((2,2))(X)\n",
    "    X=Dropout(.25)(X)\n",
    "\n",
    "    X=Conv2D(filters=128,kernel_size=(3,3),padding='same')(X)\n",
    "    X=BatchNormalization(axis=-1)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D((2,2))(X)\n",
    "    X=Dropout(.25)(X)  \n",
    "\n",
    "    X=Conv2D(filters=256,kernel_size=(3,3),padding='same')(X)\n",
    "    X=BatchNormalization(axis=-1)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=AveragePooling2D((6,6))(X) \n",
    "    X=Dropout(.25)(X)\n",
    "\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(256)(X)\n",
    "    X=BatchNormalization(axis=-1)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=Dropout(.25)(X)\n",
    "\n",
    "    X=Dense(128)(X)\n",
    "    X=BatchNormalization(axis=-1)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=Dropout(.25)(X)\n",
    "\n",
    "    X=Dense(7,'softmax')(X)\n",
    "\n",
    "    model=Model(inputs=inputs,outputs=X)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#To train a model, set False to 'load_pretrained_model',otherwise pretrained model would be loaded \n",
    "##i strictly recommend train it on GPU system,otherwise it will take a lot of time,you can use either your GPU system or google\n",
    "#colab with GPU\n",
    "load_pretrained_model=True\n",
    "\n",
    "if load_pretrained_model: \n",
    "    from tensorflow.keras.models import load_model \n",
    "    model=load_model('C:\\\\Users\\\\Admin\\\\My Projects\\\\Emotion Recognition\\\\Model\\\\model.h5')\n",
    "    print('model is loaded successfully')\n",
    "    \n",
    "else:\n",
    "    #create model with 4 conv layers and 2 FC layers\n",
    "    model=create_model() \n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    #train the model\n",
    "    num_iterations=114   \n",
    "    model.fit(X_train,Y_train_oh,batch_size=64,epochs=num_iterations,validation_split=0.08,verbose=2)\n",
    "    \n",
    "    #save model  \n",
    "    model.save('C:\\\\Users\\\\Admin\\\\My Projects\\\\Emotion Recognition\\\\Model\\\\Model.h5',save_format='h5')\n",
    "    \n",
    "    print('model is trained and saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2871/2871 [==============================] - 39s 14ms/sample - loss: 1.0629 - accuracy: 0.6660\n",
      "Accuracy =  0.66597\n"
     ]
    }
   ],
   "source": [
    "#evaluate loss and accuracy on test set\n",
    "loss,accuracy=model.evaluate(X_test,Y_test_oh)\n",
    "print('Accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Happy\n",
      "Actual class:  Happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a8e71c788>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction on test data\n",
    "pred=model.predict(X_test)     #pred contain probabilty of each classe for each example\n",
    "pred_class=np.argmax(pred,axis=1)  #one class index value for each example\n",
    "\n",
    "index=0     #you try different index value to show prediction on different test example\n",
    "\n",
    "print('Predicted class:',classes_dict[pred_class[index]])\n",
    "print('Actual class: ',classes_dict[Y_test.squeeze()[index]])\n",
    "plt.imshow(X_test[index].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of draw_boxes.Instead of this you can use cv2.rectangle() simpler and less interactive one to draw boxes\n",
    "def draw_boxes(image,out_boxes, out_classes, class_names, colors):\n",
    "    \n",
    "    font = ImageFont.truetype(font='C:\\\\Users\\Admin\\\\My Projects\\\\Emotion Recognition\\\\font\\\\FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "\n",
    "        label = predicted_class\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        #print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the emotions in single image\n",
    "def Emotion_Detector(img):\n",
    "    gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #detect faces in frame and return list of lacations of that faces\n",
    "    faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05,minNeighbors=20) \n",
    "\n",
    "    if len(faces)>0:\n",
    "            boxes=[]\n",
    "            pred=[]\n",
    "            for (x,y,w,h) in faces:\n",
    "                X=gray_img[y:y+h,x:x+w]\n",
    "                X=cv2.resize(X,(48,48)) \n",
    "                #cv2.imshow('image',X)   \n",
    "                X=X/255\n",
    "                pred.append(model.predict(X.reshape((1,48,48,1))))  #list of probabilities of each classe for each face\n",
    "                boxes.append((y,x,y+h,x+w))       #list contain location of faces\n",
    "\n",
    "            boxes=np.array(boxes)  \n",
    "            pred_classes=np.argmax(np.array(pred).squeeze(axis=1),axis=-1)\n",
    "\n",
    "            img =Image.fromarray(img,'RGB') #convert numpy array object to image object\n",
    "\n",
    "            #locate and label the faces with square box.Instead of this you can use cv2.rectangle() simpler and \n",
    "            #less interactive one to draw boxes \n",
    "            draw_boxes(img,boxes, pred_classes, classes_dict, colors_dict) \n",
    "\n",
    "            img=np.array(img)    #convert image object to array object \n",
    "\n",
    "    cv2.imshow('Emotion Detector',img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img_if_big(img):\n",
    "    return cv2.resize(img,(int(img.shape[1]/2),int(img.shape[0]/2))) if int(img.shape[1])>1500 else img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose option to detect emotions \n",
      "1.Realtime Cam \n",
      "2.Image \n",
      "3.Video\n",
      "Enter your choice : 1\n",
      "\n",
      "choose cam \n",
      "1.WebCam \n",
      "2.IP Cam\n",
      "Enter your choice : 1\n",
      "\n",
      "Press q or Q to quit \n"
     ]
    }
   ],
   "source": [
    "## now you can detect the emotions in Realtime Cam,Image and Video depend upon your choice,just run this cell and choose your choice \n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#colors(BGR) dictionary\n",
    "colors_dict={0:(0,0,255),1:(0,255,255),2:(255,0,255),3:(0,255,0),4:(255,255,0),5:(255,0,0),6:(255,255,255)}\n",
    "\n",
    "#extract face feature\n",
    "face_cascade=cv2.CascadeClassifier('C:\\\\Users\\\\Admin\\\\My Projects\\\\Emotion Recognition\\\\HararCascade\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "print('choose option to detect emotions \\n1.Realtime Cam \\n2.Image \\n3.Video')\n",
    "ch=int(input('Enter your choice : '))\n",
    "\n",
    "try:\n",
    "    key=-1\n",
    "    if ch==1:\n",
    "        print('\\nchoose cam \\n1.WebCam \\n2.IP Cam')\n",
    "        ch=int(input('Enter your choice : '))\n",
    "        try:\n",
    "            flag=1\n",
    "            if ch==1:\n",
    "                #create video object\n",
    "                video = cv2.VideoCapture(0)\n",
    "            elif ch==2:    \n",
    "                #create video object\n",
    "                video = cv2.VideoCapture(input('Enter IP Cam url: '))     #IP Cam url like http://192.168.1.100:4343/video\n",
    "            else:\n",
    "                print('\\nYou choosed wrong choice')\n",
    "                flag=0\n",
    "                \n",
    "            if flag:\n",
    "                print('\\nPress q or Q to quit ')\n",
    "                while True:\n",
    "                        check, frame = video.read()\n",
    "                        if check==False or key in [81,113]:\n",
    "                            break\n",
    "                        Emotion_Detector(frame)\n",
    "                        key=cv2.waitKey(1) \n",
    "        finally: \n",
    "            video.release()\n",
    "\n",
    "    elif ch==2:\n",
    "        print('\\nPress any key to quit ')\n",
    "        path=input('Enter Path of your Image : ').replace('\\\\','\\\\\\\\')\n",
    "        image = cv2.imread(path, 1)\n",
    "        if np.size(image)==1:\n",
    "            print('\\nyou may entered wrong path')\n",
    "        else:\n",
    "            image=resize_img_if_big(image)\n",
    "            image=Emotion_Detector(image)\n",
    "            cv2.waitKey(0) \n",
    "\n",
    "    elif ch==3:\n",
    "        path=input('\\nEnter Path of your Video : ').replace('\\\\','\\\\\\\\')\n",
    "        try:\n",
    "            #create video object\n",
    "            video = cv2.VideoCapture(path)\n",
    "            key=-1\n",
    "            while True:\n",
    "                check, frame = video.read()\n",
    "                if check==False or key in [81,113]:\n",
    "                    if not check:\n",
    "                        print('\\nyou may entered wrong path')\n",
    "                    break\n",
    "                print('\\nPress q or Q to quit ')    \n",
    "                frame=resize_img_if_big(frame)\n",
    "                Emotion_Detector(frame)\n",
    "                key=cv2.waitKey(1) \n",
    "        finally: \n",
    "            video.release()\n",
    "    else:\n",
    "        print('\\nYou choosed wrong choice')\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save the emotion detected image\n",
    "path='C:\\\\Users\\\\Admin\\\\My Projects\\\\Emotion Recognition\\\\prediction\\\\happy.jpg'\n",
    "if cv2.imwrite(path,image):\n",
    "    print('image is saved successfully')\n",
    "else:\n",
    "    print('image is not saved,enter a proper a path')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
